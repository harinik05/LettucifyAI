{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DISTRIBUTED GPU TRAINING JOB FOR FOOD DATA CLASSIFICATION \n",
    "\n",
    "The purpose of this notebook is to provide a technical documentation for a greater accelerated training process. This is done through a methodological approach known as distributed GPU training process. This involves a multi-node multi-gpu pytorch job, wherin MLFlow was used to analyze the metrics.  \n",
    "\n",
    "**Requirements & Dependencies:**\n",
    "1. Provisioned AzureML workspace with Azure subscription\n",
    "2. Appropriate permissions to provision minimal CPU and GPU cluster \n",
    "3. Azure ML Python SDK V2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONNECTION TO AZUREML CLIENT üîó\n",
    "\n",
    "An instance of the MLClient was created to connect to AzureML service. The use of `DefaultAzureCredential` is used to access the workspace and resource wherin the code is located in. This service principle policy allows the user to authenticate to access the client in a secured manner. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the required libraries for this auth step\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "\n",
    "# tru catch method to retrieve this form of connection with a token\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "\n",
    "# when this form of connection doesn't work, it will prompt a manual login\n",
    "except Exception as error:\n",
    "    credential = InteractiveBrowserCredential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the ml client library\n",
    "from azure.ai.ml import MLClient\n",
    "\n",
    "# Prepare the information needed to access it in the account\n",
    "ml_client = MLClient(\n",
    "    subscription_id=\"<SUBSCRIPTION_ID>\",\n",
    "    resource_group_name=\"resource1\",\n",
    "    workspace_name=\"workspace1\",\n",
    "    credential=credential,\n",
    ")\n",
    "cpu_cluster = None\n",
    "gpu_cluster = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATION OF CLUSTERS üéØ\n",
    "There are two types of clusters on Azure that are required for this project. This includes CPU and GPU cluster. \n",
    "\n",
    "1. **CPU**: Consists of VMs to handle computing tasks such as running applications, handling web applications, and performing data processing. Don't rely on parallel processing. \n",
    "\n",
    "2. **GPU**: Consists of VMs for parallel processing and for heavy computation work such as ML, scientific simulations, video rendering, etc. Azure uses the NVIDIA Tesla series as a VM to perform deep learning tasks. VMs are software-emulation of physical computers that run on their own OS(guest OS) and runs independently of other VMs in the same host machine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new CPU compute target...\n",
      "The compute with the name is project-cpu-cluster is made and the size is STANDARD_DS3_V2\n"
     ]
    }
   ],
   "source": [
    "# Import the cpu library from Azure\n",
    "from azure.ai.ml.entities import AmlCompute\n",
    "\n",
    "cpu_compute_target = \"project-cpu-cluster\"\n",
    "\n",
    "# Determine if the compute target already exists and return a message for it\n",
    "try:\n",
    "    cpu_cluster = ml_client.compute.get(cpu_compute_target)\n",
    "    print(f\"You already have a cluster of the same name which is {cpu_compute_target}\")\n",
    "\n",
    "# We're not catching an error, but its an exception  \n",
    "except Exception:\n",
    "    print(\"Creating a new CPU compute target...\")\n",
    "\n",
    "    # Create an Azure ML Compute Object \n",
    "    cpu_cluster = AmlCompute(\n",
    "        # Name of cluster\n",
    "        name = \"{cpu_compute_target}\",\n",
    "\n",
    "        # Describe the VM service \n",
    "        type = \"amlcompute\",\n",
    "\n",
    "        # VM Family\n",
    "        size = \"STANDARD_DS3_V2\",\n",
    "\n",
    "        # Min nodes \n",
    "        min_instances = 0,\n",
    "\n",
    "        # Max nodes\n",
    "        max_instances = 5,\n",
    "\n",
    "        #Time for node to run after job has been terminated\n",
    "        idle_time_before_scale_down = 200,\n",
    "\n",
    "        # Define the cost tier - LowPriority or Dedicated. \n",
    "        tier = \"Dedicated\",\n",
    "    )\n",
    "\n",
    "    # Pass the object to the MLClient for creation and updation\n",
    "    cpu_cluster_client = ml_client.begin_create_or_update(cpu_cluster)\n",
    "\n",
    "# print statement in the end to show the success of creation \n",
    "print(f\"The compute with the name is {cpu_cluster_client.name} is made and the size is {cpu_cluster_client.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new gpu compute target...\n",
      "AML Compute with the name project-gpu-cluster and the size of STANDARD_NC6s_v3\n"
     ]
    }
   ],
   "source": [
    "# Import the required libraries for AML compute\n",
    "from azure.ai.ml.entities import AmlCompute\n",
    "\n",
    "gpu_cluster_target = \"project-gpu-cluster\"\n",
    "\n",
    "# check if the gpu cluster exists\n",
    "try:\n",
    "    gpu_cluster = ml_client.compute.get(gpu_cluster_target)\n",
    "    print(f\"Theres a gpu clusterwith a name {gpu_cluster_target} that already exists\")\n",
    "\n",
    "\n",
    "# compute using gpu compute cluster by making one\n",
    "except Exception:\n",
    "    print(\"Creating a new gpu compute target...\")\n",
    "\n",
    "    gpu_cluster = AmlCompute(\n",
    "        # Name of cluster\n",
    "        name = \"project-gpu-cluster\", \n",
    "\n",
    "        # Describe the VM service \n",
    "        type = \"amlcompute\",\n",
    "\n",
    "        # VM Family\n",
    "        size = \"STANDARD_NC6s_v3\",\n",
    "\n",
    "        # Min number of nodes\n",
    "        min_instances = 0,\n",
    "\n",
    "        # Max number of nodes\n",
    "        max_instances = 5,\n",
    "\n",
    "        #Time for node to run after job has been terminated\n",
    "        idle_time_before_scale_down = 200,\n",
    "\n",
    "        # Define the cost tier\n",
    "        tier = \"Dedicated\",\n",
    "\n",
    "    )\n",
    "\n",
    "    # pass the object to the ml client\n",
    "    gpu_cluster_client = ml_client.begin_create_or_update(gpu_cluster)\n",
    "\n",
    "print(f\"AML Compute with the name {gpu_cluster_client.name} and the size of {gpu_cluster_client.size} \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNZIPPING IMAGE ARCHIVES üñºÔ∏è\n",
    "To train the machine learning classifier, it is crucial to take in the dataset from local and extract the zip archive before putting them in train and validation folder. \n",
    "\n",
    "```\n",
    "tar xvfm ${{inputs.archive}} --no-same-owner -C ${{outputs.images}}\n",
    "```\n",
    "\n",
    "Parameters like the location of archive and output directory are injected into the command using the command. This is applied further in the code itself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating command job for unzipping files...\n",
      "Command job created successfully.\n"
     ]
    }
   ],
   "source": [
    "# import the required libraries\n",
    "from azure.ai.ml import command \n",
    "from azure.ai.ml import Input, Output\n",
    "from azure.ai.ml.constants import AssetTypes \n",
    "\n",
    "# Command for unzipping the files in the directory\n",
    "dataset_untar_command_jar = command(\n",
    "    # Name for the UI (optional)\n",
    "    display_name = \"untarring_command\",\n",
    "\n",
    "    # apply the command\n",
    "    command = \"tar xvfm ${{inputs.archive}} --no-same-owner -C ${{outputs.images}}\",\n",
    "\n",
    "    # inputs\n",
    "    inputs = {\n",
    "        \"archive\": Input(\n",
    "            type = AssetTypes.URI_FILE, \n",
    "            path = \"https://drive.google.com/file/d/1BGnigrVXeQ-Oeh04wIyG0HcEH4_f_kgf/view?usp=sharing\"\n",
    "        )\n",
    "    },\n",
    "\n",
    "    # outputs \n",
    "    outputs = {\n",
    "        \"images\": Output(\n",
    "            type = AssetTypes.URI_FOLDER,\n",
    "            mode = \"upload\",\n",
    "            path=\"azureml://datastores/workspaceblobstore/paths/datasets\",\n",
    "\n",
    "        ),\n",
    "    },\n",
    "\n",
    "    # define the environment\n",
    "    environment = \"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu:1\",\n",
    "\n",
    "    # define the compute (Lambda Expression in Python)\n",
    "    compute = lambda client: \"project-cpu-cluster\" if client else None\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the URL for the live job.... \n",
      "The pipeline details can be accessed through the job: food-classification\n"
     ]
    }
   ],
   "source": [
    "# import the required libraries\n",
    "import webbrowser\n",
    "\n",
    "# submit the required command object to the ml client\n",
    "job_object = ml_client.create_or_update(dataset_untar_command_jar)\n",
    "\n",
    "# obtain the URL for job status to unzip the files\n",
    "print(f\"Here is the URL for the live job.... {job_object.studio_url}\")\n",
    "\n",
    "# Open the browser with this URL \n",
    "webbrowser.open(job_object.studio_url)\n",
    "\n",
    "#print the pipeline\n",
    "print(f\"The pipeline details can be accessed through the job: {job_object.name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DISTRIBUTED GPU TRAINING JOB ü§ñ\n",
    "Distributed training can be completed in a bunch of different ways that include "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "train_src_dir = \"/Users/harinikarthik/Desktop/Waterloo/Leetcode/Smart-Fridge/SRC\"\n",
    "os.makedirs(train_src_dir, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {train_src_dir}/main.py\n",
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, DistributedSampler\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(32 * 128 * 128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 16)  # Output size 16 for 16 classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function of the script.\"\"\"\n",
    "    # input and output arguments\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--data\", type=str, help=\"path to input data\")\n",
    "    parser.add_argument(\"--batch_size\", type=int, help=\"batch size\")\n",
    "    parser.add_argument(\"--num_workers\", type=int, help=\"number of workers\")\n",
    "    parser.add_argument(\"--prefetch_factor\", type=int, help=\"prefetch factor\")\n",
    "    parser.add_argument(\"--model_arch\", type=str, help=\"model architecture\")\n",
    "    parser.add_argument(\"--model_arch_pretrained\", type=bool, help=\"whether to use pretrained model architecture\")\n",
    "    parser.add_argument(\"--num_epochs\", type=int, help=\"number of epochs\")\n",
    "    parser.add_argument(\"--learning_rate\", type=float, help=\"learning rate\")\n",
    "    parser.add_argument(\"--momentum\", type=float, help=\"momentum\")\n",
    "    parser.add_argument(\"--register_model_as\", type=str, help=\"model registration name\")\n",
    "    parser.add_argument(\"--enable_profiling\", type=bool, help=\"whether to enable profiling\")\n",
    "    args = parser.parse_args()\n",
    "   \n",
    "    # Initialize distributed backend\n",
    "    torch.distributed.init_process_group(backend='nccl')\n",
    "\n",
    "    # Start Logging\n",
    "    mlflow.start_run()\n",
    "\n",
    "    ###################\n",
    "    #<prepare the data>\n",
    "    ###################\n",
    "    print(\" \".join(f\"{k}={v}\" for k, v in vars(args).items()))\n",
    "\n",
    "    print(\"input data:\", args.data)\n",
    "    \n",
    "    # Assuming you have a train dataset in args.data directory\n",
    "    train_dataset = torchvision.datasets.ImageFolder(\n",
    "        root=args.data,\n",
    "        transform=transforms.Compose([\n",
    "                      transforms.ToTensor(),\n",
    "                      transforms.Resize((512, 512))\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    # Use DistributedSampler for distributed training\n",
    "    train_sampler = DistributedSampler(train_dataset)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, sampler=train_sampler, \n",
    "                              num_workers=args.num_workers, prefetch_factor=args.prefetch_factor)\n",
    "    ####################\n",
    "    #</prepare the data>\n",
    "    ####################\n",
    "\n",
    "    ##################\n",
    "    #<train the model>\n",
    "    ##################\n",
    "    model = CNNModel()\n",
    "    \n",
    "    # Wrap model with DistributedDataParallel\n",
    "    model = DistributedDataParallel(model)\n",
    "\n",
    "    # Loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate, momentum=args.momentum)\n",
    "\n",
    "    # Training loop\n",
    "    loss = None\n",
    "    for epoch in range(args.num_epochs):\n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    ###################\n",
    "    #</train the model>\n",
    "    ###################\n",
    "\n",
    "    ##########################\n",
    "    #<save and register model>\n",
    "    ##########################\n",
    "    # Save the trained model\n",
    "    torch.save(model.state_dict(), \"trained_model.pth\")\n",
    "\n",
    "    # Registering the model to the workspace\n",
    "    print(\"Registering the model via MLFlow\")\n",
    "    mlflow.pytorch.log_model(model, args.register_model_as)\n",
    "\n",
    "    # Saving the model to a file\n",
    "    mlflow.pytorch.save_model(model, args.register_model_as)\n",
    "    ###########################\n",
    "    #</save and register model>\n",
    "    ###########################\n",
    "    \n",
    "    # Log training loss\n",
    "    mlflow.log_metric(\"training_loss\", loss.item())\n",
    "    \n",
    "    # Stop Logging\n",
    "    mlflow.end_run()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import command\n",
    "from azure.ai.ml import Input\n",
    "from azure.ai.ml.entities import ResourceConfiguration\n",
    "\n",
    "training_job = command(\n",
    "    # local path where the code is stored\n",
    "    code=\"./src/pytorch_dl_train/\",\n",
    "    # describe the command to run the python script, with all its parameters\n",
    "    # use the syntax below to inject parameter values from code\n",
    "    command=\"\"\"python train.py \\\n",
    "        --train_images ${{inputs.train_images}} \\\n",
    "        --batch_size ${{inputs.batch_size}} \\\n",
    "        --num_workers ${{inputs.num_workers}} \\\n",
    "        --prefetch_factor ${{inputs.prefetch_factor}} \\\n",
    "        --model_arch ${{inputs.model_arch}} \\\n",
    "        --model_arch_pretrained ${{inputs.model_arch_pretrained}} \\\n",
    "        --num_epochs ${{inputs.num_epochs}} \\\n",
    "        --learning_rate ${{inputs.learning_rate}} \\\n",
    "        --momentum ${{inputs.momentum}} \\\n",
    "        --register_model_as ${{inputs.register_model_as}} \\\n",
    "        --enable_profiling ${{inputs.enable_profiling}}\n",
    "    \"\"\",\n",
    "    inputs={\n",
    "        \"train_images\": Input(\n",
    "            type=\"uri_folder\",\n",
    "            path=\"Users/guess_karthik/AzureML/src\",\n",
    "            # path=\"azureml://datastores/workspaceblobstore/paths/tutorial-datasets/places2/train/\",\n",
    "            mode=\"download\",  # use download to make access faster, mount if dataset is larger than VM\n",
    "        ),\n",
    "        \"batch_size\": 64,\n",
    "        \"num_workers\": 5,  # number of cpus for pre-fetching\n",
    "        \"prefetch_factor\": 2,  # number of batches fetched in advance\n",
    "        \"model_arch\": \"resnet18\",\n",
    "        \"model_arch_pretrained\": True,\n",
    "        \"num_epochs\": 7,\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"momentum\": 0.01,\n",
    "        \"register_model_as\": \"dogs_dev\",\n",
    "        # \"register_model_as\": \"places_dev\",\n",
    "        \"enable_profiling\": False,\n",
    "    },\n",
    "    environment=\"AzureML-pytorch-1.10-ubuntu18.04-py38-cuda11-gpu@latest\",\n",
    "    compute=\"gpu-cluster\"\n",
    "    if (gpu_cluster)\n",
    "    else None,  # No compute needs to be passed to use serverless\n",
    "    distribution={\n",
    "        \"type\": \"PyTorch\",\n",
    "        # set process count to the number of gpus on the node\n",
    "        # NC6 has only 1\n",
    "        \"process_count_per_instance\": 1,\n",
    "    },\n",
    "    # set instance count to the number of nodes you want to use\n",
    "    instance_count=2,\n",
    "    display_name=\"pytorch_training_sample\",\n",
    "    description=\"training a torchvision model\",\n",
    ")\n",
    "if gpu_cluster == None:\n",
    "    training_job.resources = ResourceConfiguration(\n",
    "        instance_type=\"Standard_NC6s_v3\", instance_count=2\n",
    "    )  # resources for serverless job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading src (0.01 MBs):   0%|          | 0/5613 [00:00<?, ?it/s]\n",
      "Uploading src (0.01 MBs): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5613/5613 [00:00<00:00, 425972.14it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_a358c th {\n",
       "  background-color: dimgray;\n",
       "  color: white;\n",
       "  text-align: center;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_a358c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_a358c_level0_col0\" class=\"col_heading level0 col0\" >Experiment</th>\n",
       "      <th id=\"T_a358c_level0_col1\" class=\"col_heading level0 col1\" >Name</th>\n",
       "      <th id=\"T_a358c_level0_col2\" class=\"col_heading level0 col2\" >Type</th>\n",
       "      <th id=\"T_a358c_level0_col3\" class=\"col_heading level0 col3\" >Status</th>\n",
       "      <th id=\"T_a358c_level0_col4\" class=\"col_heading level0 col4\" >Details Page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_a358c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_a358c_row0_col0\" class=\"data row0 col0\" >Foods-Project</td>\n",
       "      <td id=\"T_a358c_row0_col1\" class=\"data row0 col1\" >quirky_night_36q3t31071</td>\n",
       "      <td id=\"T_a358c_row0_col2\" class=\"data row0 col2\" >command</td>\n",
       "      <td id=\"T_a358c_row0_col3\" class=\"data row0 col3\" >Starting</td>\n",
       "      <td id=\"T_a358c_row0_col4\" class=\"data row0 col4\" ><a href=\"https://ml.azure.com/runs?wsid=/subscriptions/1442df46-ca82-4ac8-88ee-d46af11321d5/resourceGroups/resource1/providers/Microsoft.MachineLearningServices/workspaces/workplace1&tid=628e456a-64f2-4950-8f77-48f351de2de8#:~:text=%EF%84%BE-,food_classification_model,-%EE%9C%8F\">Link to Azure Machine Learning studio</a></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_a358c_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_a358c_row1_col0\" class=\"data row1 col0\" >Foods-Project</td>\n",
       "      <td id=\"T_a358c_row1_col1\" class=\"data row1 col1\" >quirky_night_36q3t31072</td>\n",
       "      <td id=\"T_a358c_row1_col2\" class=\"data row1 col2\" >command</td>\n",
       "      <td id=\"T_a358c_row1_col3\" class=\"data row1 col3\" >Starting</td>\n",
       "      <td id=\"T_a358c_row1_col4\" class=\"data row1 col4\" ><a href=\"https://ml.azure.com/runs?wsid=/subscriptions/1442df46-ca82-4ac8-88ee-d46af11321d5/resourceGroups/resource1/providers/Microsoft.MachineLearningServices/workspaces/workplace1&tid=628e456a-64f2-4950-8f77-48f351de2de8#:~:text=%EF%84%BE-,food_classification_model,-%EE%9C%8F\">Link to Azure Machine Learning studio</a></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x168da8f90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ml_client.jobs.create_or_update(training_job)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an Online Endpoint for real-time inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "# Creating a unique name for the endpoint\n",
    "online_endpoint_name = \"food-endpoint-\" + str(uuid.uuid4())[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint food-endpoint-7880d4a9 provisioning state: Succeeded\n"
     ]
    }
   ],
   "source": [
    "# Expect the endpoint creation to take a few minutes\n",
    "from azure.ai.ml.entities import (\n",
    "    ManagedOnlineEndpoint,\n",
    "    ManagedOnlineDeployment,\n",
    "    Model,\n",
    "    Environment,\n",
    ")\n",
    "\n",
    "# create an online endpoint\n",
    "endpoint = ManagedOnlineEndpoint(\n",
    "    name=online_endpoint_name,\n",
    "    description=\"this is an online endpoint\",\n",
    "    auth_mode=\"key\",\n",
    "    tags={\n",
    "        \"training_dataset\": \"credit_defaults\",\n",
    "        \"model_type\": \"torch.nn.Sequential\",\n",
    "    },\n",
    ")\n",
    "\n",
    "endpoint = ml_client.online_endpoints.begin_create_or_update(endpoint).result()\n",
    "\n",
    "print(f\"Endpoint {endpoint.name} provisioning state: {endpoint.provisioning_state}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint \"food-endpoint-7880d4a9\" with provisioning state \"Succeeded\" is retrieved\n"
     ]
    }
   ],
   "source": [
    "endpoint = ml_client.online_endpoints.get(name=online_endpoint_name)\n",
    "\n",
    "print(\n",
    "    f'Endpoint \"{endpoint.name}\" with provisioning state \"{endpoint.provisioning_state}\" is retrieved'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: azureml_mango_shirt_vhw92tbjc8_output_mlflow_log_model_1974916105, Version: None, Description: None\n",
      "Name: azureml_mango_shirt_vhw92tbjc8_output_mlflow_log_model_1974916105, Version: 2, Description: None\n",
      "Name: azureml_mango_shirt_vhw92tbjc8_output_mlflow_log_model_1099368587, Version: None, Description: None\n",
      "Name: azureml_mango_shirt_vhw92tbjc8_output_mlflow_log_model_1099368587, Version: 2, Description: None\n",
      "Name: credit_defaults_model, Version: None, Description: None\n",
      "Name: credit_defaults_model, Version: 2, Description: None\n",
      "Name: azureml_wheat_garden_dmr7j4sjgl_output_mlflow_log_model_1982509246, Version: None, Description: None\n",
      "Name: azureml_wheat_garden_dmr7j4sjgl_output_mlflow_log_model_1982509246, Version: 2, Description: None\n",
      "Name: azureml_teal_market_mpkbjj7gmb_output_mlflow_log_model_1893551161, Version: None, Description: None\n",
      "Name: azureml_teal_market_mpkbjj7gmb_output_mlflow_log_model_1893551161, Version: 2, Description: None\n",
      "Name: azureml_elated_parsnip_vv3s61rxjb_output_mlflow_log_model_1598139841, Version: None, Description: None\n",
      "Name: azureml_elated_parsnip_vv3s61rxjb_output_mlflow_log_model_1598139841, Version: 2, Description: None\n",
      "Name: azureml_quirky_night_36q3t31071_output_mlflow_log_model_458298590, Version: None, Description: None\n",
      "Name: azureml_quirky_night_36q3t31071_output_mlflow_log_model_458298590, Version: 2, Description: None\n"
     ]
    }
   ],
   "source": [
    "# List all models\n",
    "all_models = ml_client.models.list()\n",
    "\n",
    "# Iterate over the models and print their details\n",
    "for model in all_models:\n",
    "    print(f\"Name: {model.name}, Version: {model.version}, Description: {model.description}\")\n",
    "    model.version = \"2\"\n",
    "    print(f\"Name: {model.name}, Version: {model.version}, Description: {model.description}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check: endpoint food-endpoint-7880d4a9 exists\n",
      "................................................................................................................................................................................................................................................\n",
      "................................................................................................................................................................................................................................................\n",
      "................................................................................................................................................................................................................................................\n",
      "................................................................................................................................................................................................................................................\n"
     ]
    }
   ],
   "source": [
    "# picking the model to deploy. Here we use the latest version of our registered model\n",
    "model = ml_client.models.get(name=\"Food_Model\", version = \"1\")\n",
    "\n",
    "# Expect this deployment to take approximately 6 to 8 minutes.\n",
    "# create an online deployment.\n",
    "# if you run into an out of quota error, change the instance_type to a comparable VM that is available.\n",
    "# Learn more on https://azure.microsoft.com/en-us/pricing/details/machine-learning/.\n",
    "blue_deployment = ManagedOnlineDeployment(\n",
    "    name=\"bluenew\",\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    model=model,\n",
    "    instance_type=\"Standard_E2s_v3\",\n",
    "    instance_count=1,\n",
    ")\n",
    "\n",
    "blue_deployment = ml_client.begin_create_or_update(blue_deployment).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
