{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DISTRIBUTED GPU TRAINING JOB FOR FOOD DATA CLASSIFICATION \n",
    "\n",
    "The purpose of this notebook is to provide a technical documentation for a greater accelerated training process. This is done through a methodological approach known as distributed GPU training process. This involves a multi-node multi-gpu pytorch job, wherin MLFlow was used to analyze the metrics.  \n",
    "\n",
    "**Requirements & Dependencies:**\n",
    "1. Provisioned AzureML workspace with Azure subscription\n",
    "2. Appropriate permissions to provision minimal CPU and GPU cluster \n",
    "3. Azure ML Python SDK V2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONNECTION TO AZUREML CLIENT üîó\n",
    "\n",
    "An instance of the MLClient was created to connect to AzureML service. The use of `DefaultAzureCredential` is used to access the workspace and resource wherin the code is located in. This service principle policy allows the user to authenticate to access the client in a secured manner. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the required libraries for this auth step\n",
    "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
    "\n",
    "# tru catch method to retrieve this form of connection with a token\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "\n",
    "# when this form of connection doesn't work, it will prompt a manual login\n",
    "except Exception as error:\n",
    "    credential = InteractiveBrowserCredential()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Import the ml client library\n",
    "from azure.ai.ml import MLClient\n",
    "\n",
    "# Prepare the information needed to access it in the account\n",
    "ml_client = MLClient(\n",
    "    subscription_id=\"<SUBSCRIPTION_ID>\",\n",
    "    resource_group_name=\"resource1\",\n",
    "    workspace_name=\"workspace1\",\n",
    "    credential=credential,\n",
    ")\n",
    "cpu_cluster = None\n",
    "gpu_cluster = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATION OF CLUSTERS üéØ\n",
    "There are two types of clusters on Azure that are required for this project. This includes CPU and GPU cluster. \n",
    "\n",
    "1. **CPU**: Consists of VMs to handle computing tasks such as running applications, handling web applications, and performing data processing. Don't rely on parallel processing. \n",
    "\n",
    "2. **GPU**: Consists of VMs for parallel processing and for heavy computation work such as ML, scientific simulations, video rendering, etc. Azure uses the NVIDIA Tesla series as a VM to perform deep learning tasks. VMs are software-emulation of physical computers that run on their own OS(guest OS) and runs independently of other VMs in the same host machine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new CPU compute target...\n",
      "The compute with the name is project-cpu-cluster is made and the size is STANDARD_DS3_V2\n"
     ]
    }
   ],
   "source": [
    "# Import the cpu library from Azure\n",
    "from azure.ai.ml.entities import AmlCompute\n",
    "\n",
    "cpu_compute_target = \"project-cpu-cluster\"\n",
    "\n",
    "# Determine if the compute target already exists and return a message for it\n",
    "try:\n",
    "    cpu_cluster = ml_client.compute.get(cpu_compute_target)\n",
    "    print(f\"You already have a cluster of the same name which is {cpu_compute_target}\")\n",
    "\n",
    "# We're not catching an error, but its an exception  \n",
    "except Exception:\n",
    "    print(\"Creating a new CPU compute target...\")\n",
    "\n",
    "    # Create an Azure ML Compute Object \n",
    "    cpu_cluster = AmlCompute(\n",
    "        # Name of cluster\n",
    "        name = \"{cpu_compute_target}\",\n",
    "\n",
    "        # Describe the VM service \n",
    "        type = \"amlcompute\",\n",
    "\n",
    "        # VM Family\n",
    "        size = \"STANDARD_DS3_V2\",\n",
    "\n",
    "        # Min nodes \n",
    "        min_instances = 0,\n",
    "\n",
    "        # Max nodes\n",
    "        max_instances = 5,\n",
    "\n",
    "        #Time for node to run after job has been terminated\n",
    "        idle_time_before_scale_down = 200,\n",
    "\n",
    "        # Define the cost tier - LowPriority or Dedicated. \n",
    "        tier = \"Dedicated\",\n",
    "    )\n",
    "\n",
    "    # Pass the object to the MLClient for creation and updation\n",
    "    cpu_cluster_client = ml_client.begin_create_or_update(cpu_cluster)\n",
    "\n",
    "# print statement in the end to show the success of creation \n",
    "print(f\"The compute with the name is {cpu_cluster_client.name} is made and the size is {cpu_cluster_client.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new gpu compute target...\n",
      "AML Compute with the name project-gpu-cluster and the size of STANDARD_NC6s_v3\n"
     ]
    }
   ],
   "source": [
    "# Import the required libraries for AML compute\n",
    "from azure.ai.ml.entities import AmlCompute\n",
    "\n",
    "gpu_cluster_target = \"project-gpu-cluster\"\n",
    "\n",
    "# check if the gpu cluster exists\n",
    "try:\n",
    "    gpu_cluster = ml_client.compute.get(gpu_cluster_target)\n",
    "    print(f\"Theres a gpu clusterwith a name {gpu_cluster_target} that already exists\")\n",
    "\n",
    "\n",
    "# compute using gpu compute cluster by making one\n",
    "except Exception:\n",
    "    print(\"Creating a new gpu compute target...\")\n",
    "\n",
    "    gpu_cluster = AmlCompute(\n",
    "        # Name of cluster\n",
    "        name = \"project-gpu-cluster\", \n",
    "\n",
    "        # Describe the VM service \n",
    "        type = \"amlcompute\",\n",
    "\n",
    "        # VM Family\n",
    "        size = \"STANDARD_NC6s_v3\",\n",
    "\n",
    "        # Min number of nodes\n",
    "        min_instances = 0,\n",
    "\n",
    "        # Max number of nodes\n",
    "        max_instances = 5,\n",
    "\n",
    "        #Time for node to run after job has been terminated\n",
    "        idle_time_before_scale_down = 200,\n",
    "\n",
    "        # Define the cost tier\n",
    "        tier = \"Dedicated\",\n",
    "\n",
    "    )\n",
    "\n",
    "    # pass the object to the ml client\n",
    "    gpu_cluster_client = ml_client.begin_create_or_update(gpu_cluster)\n",
    "\n",
    "print(f\"AML Compute with the name {gpu_cluster_client.name} and the size of {gpu_cluster_client.size} \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNZIPPING IMAGE ARCHIVES üñºÔ∏è\n",
    "To train the machine learning classifier, it is crucial to take in the dataset from local and extract the zip archive before putting them in train and validation folder. \n",
    "\n",
    "```\n",
    "tar xvfm ${{inputs.archive}} --no-same-owner -C ${{outputs.images}}\n",
    "```\n",
    "\n",
    "Parameters like the location of archive and output directory are injected into the command using the command. This is applied further in the code itself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating command job for unzipping files...\n",
      "Command job created successfully.\n"
     ]
    }
   ],
   "source": [
    "# import the required libraries\n",
    "from azure.ai.ml import command \n",
    "from azure.ai.ml import Input, Output\n",
    "from azure.ai.ml.constants import AssetTypes \n",
    "\n",
    "# Command for unzipping the files in the directory\n",
    "dataset_untar_command_jar = command(\n",
    "    # Name for the UI (optional)\n",
    "    display_name = \"untarring_command\",\n",
    "\n",
    "    # apply the command\n",
    "    command = \"tar xvfm ${{inputs.archive}} --no-same-owner -C ${{outputs.images}}\",\n",
    "\n",
    "    # inputs\n",
    "    inputs = {\n",
    "        \"archive\": Input(\n",
    "            type = AssetTypes.URI_FILE, \n",
    "            path = \"https://drive.google.com/file/d/1BGnigrVXeQ-Oeh04wIyG0HcEH4_f_kgf/view?usp=sharing\"\n",
    "        )\n",
    "    },\n",
    "\n",
    "    # outputs \n",
    "    outputs = {\n",
    "        \"images\": Output(\n",
    "            type = AssetTypes.URI_FOLDER,\n",
    "            mode = \"upload\",\n",
    "            path=\"azureml://datastores/workspaceblobstore/paths/datasets\",\n",
    "\n",
    "        ),\n",
    "    },\n",
    "\n",
    "    # define the environment\n",
    "    environment = \"AzureML-sklearn-1.0-ubuntu20.04-py38-cpu:1\",\n",
    "\n",
    "    # define the compute (Lambda Expression in Python)\n",
    "    compute = lambda client: \"project-cpu-cluster\" if client else None\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the URL for the live job.... https://ml.azure.com/runs/modest_turtle_h5757766x3?wsid=/subscriptions/1442df46-ca82-4ac8-88ee-d46af11321d5/resourcegroups/resource1/providers/Microsoft.MachineLearningServices/workspaces/workplace1&tid=628e456a-64f2-4950-8f77-48f351de2de8\n",
      "The pipeline details can be accessed through the job: untarring_command\n"
     ]
    }
   ],
   "source": [
    "# import the required libraries\n",
    "import webbrowser\n",
    "\n",
    "# submit the required command object to the ml client\n",
    "job_object = ml_client.create_or_update(dataset_untar_command_jar)\n",
    "\n",
    "# obtain the URL for job status to unzip the files\n",
    "print(f\"Here is the URL for the live job.... {job_object.studio_url}\")\n",
    "\n",
    "# Open the browser with this URL \n",
    "webbrowser.open(job_object.studio_url)\n",
    "\n",
    "#print the pipeline\n",
    "print(f\"The pipeline details can be accessed through the job: {job_object.name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DISTRIBUTED GPU TRAINING JOB ü§ñ\n",
    "Distributed training can be completed in a bunch of different ways that include "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
